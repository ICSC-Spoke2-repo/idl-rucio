#!/usr/bin/env python3

################# WARNING ##################
# FOR NOW I'M DISABLING THE HTTPS CONNCECTION WARNING, BUT THIS CAN HIDE SOME REAL HTTPS ISSUES!!!
import urllib3
import warnings
# Suppress only the InsecureRequestWarning from urllib3
warnings.filterwarnings('ignore', message='Unverified HTTPS request', category=urllib3.exceptions.InsecureRequestWarning)
############################################

import argparse
import errno
import itertools
import logging
import math
import os
import signal
import subprocess
import sys
import time
import traceback
import unittest
import uuid
from configparser import NoOptionError, NoSectionError
from copy import deepcopy
from datetime import datetime
from functools import wraps

from tabulate import tabulate

from rucio import version
from rucio.client import Client
from rucio.common.config import config_get, config_get_float
from rucio.common.constants import ReplicaState
from rucio.common import exception
from rucio.common.exception import (
    AccessDenied,
    CannotAuthenticate,
    DatabaseException,
    DataIdentifierAlreadyExists,
    DataIdentifierNotFound,
    DIDFilterSyntaxError,
    DuplicateContent,
    DuplicateCriteriaInDIDFilter,
    DuplicateRule,
    InputValidationError,
    InvalidObject,
    InvalidRSEExpression,
    InvalidType,
    MissingDependency,
    NoFilesUploaded,
    NotAllFilesUploaded,
    RSENotFound,
    RucioException,
    RuleNotFound,
    UnsupportedOperation
)
from rucio.common.extra import import_extras
from rucio.common.test_rucio_server import TestRucioServer
from rucio.common.utils import sha256, Color, StoreAndDeprecateWarningAction, chunks, detect_client_location, extract_scope, parse_did_filter_from_string, parse_did_filter_from_string_fe, setup_logger, sizefmt

EXTRA_MODULES = import_extras(['argcomplete'])

if EXTRA_MODULES['argcomplete']:
    import argcomplete  # pylint: disable=E0401

# Imports for the custom client
import argcomplete
import json
import ast
import re
import os
import numpy as np

# Dynamically retrieving the list of rucio and rucio-admin commands
result = subprocess.run(["rucio", "--help"], capture_output=True, text=True)

for idx, line in enumerate(result.stdout.splitlines(), 1):
    if "positional arguments:" in line:
        line_with_arguments = result.stdout.splitlines()[idx].replace("positional arguments:", "").replace(" ", "")
        RUCIO_COMMANDS = line_with_arguments.replace("{","").replace("}", "").split(",")
        break

RUCIO_COMMANDS.extend(["-h", "--help", "--version"])

result_admin = subprocess.run(["rucio-admin", "--help"], capture_output=True, text=True)

for idx, line in enumerate(result_admin.stdout.splitlines(), 1):
    if "positional arguments:" in line:
        line_with_arguments = result_admin.stdout.splitlines()[idx].replace("positional arguments:", "").replace(" ", "")
        RUCIO_ADMIN_COMMANDS = line_with_arguments.replace("{","").replace("}", "").split(",")
        break

IDL_COMMANDS = ["upload", "download", "get-metadata", "list-dids", "sql", "delete-metadata"] # add "set-meta" if needed

SUCCESS = 0
FAILURE = 1

DEFAULT_SECURE_PORT = 443
DEFAULT_PORT = 80

# Configure logging to not include the logger name and only show the message
logging.basicConfig(level=logging.ERROR, format='%(message)s')

logger = logging.log
gfal2_logger = logging.getLogger("gfal2")
tablefmt = 'psql'


def setup_gfal2_logger(logger):
    logger.setLevel(logging.CRITICAL)
    logger.addHandler(logging.StreamHandler())


setup_gfal2_logger(gfal2_logger)


def signal_handler(sig, frame):
    logger.warning('You pressed Ctrl+C! Exiting gracefully')
    child_processes = subprocess.Popen('ps -o pid --ppid %s --noheaders' % os.getpid(), shell=True, stdout=subprocess.PIPE)
    child_processes = child_processes.stdout.read()
    for pid in child_processes.split("\n")[:-1]:
        try:
            os.kill(int(pid), signal.SIGTERM)
        except Exception:
            print('Cannot kill child process')
    sys.exit(1)


signal.signal(signal.SIGINT, signal_handler)


def get_scope(did, client):
    try:
        scope, name = extract_scope(did)
        return scope, name
    except TypeError:
        scopes = client.list_scopes()
        scope, name = extract_scope(did, scopes)
        return scope, name
    return None, did


def exception_handler(function):
    @wraps(function)
    def new_funct(*args, **kwargs):
        try:
            return function(*args, **kwargs)
        except InvalidObject as error:
            logger.error(error)
            return error.error_code
        except DataIdentifierNotFound as error:
            logger.error(error)
            logger.debug('This means that the Data IDentifier you provided is not known by Rucio.')
            return error.error_code
        except AccessDenied as error:
            logger.error(error)
            logger.debug('This error is a permission issue. You cannot run this command with your account.')
            return error.error_code
        except DataIdentifierAlreadyExists as error:
            logger.error(error)
            logger.debug('This means that the Data IDentifier you try to add is already registered in Rucio.')
            return error.error_code
        except RSENotFound as error:
            logger.error(error)
            logger.debug('This means that the Rucio Storage Element you provided is not known by Rucio.')
            return error.error_code
        except InvalidRSEExpression as error:
            logger.error(error)
            logger.debug('This means the RSE expression you provided is not syntactically correct.')
            return error.error_code
        except DuplicateContent as error:
            logger.error(error)
            logger.debug('This means that the DID you want to attach is already in the target DID.')
            return error.error_code
        except TypeError as error:
            logger.error(error)
            logger.debug('This means the parameter you passed has a wrong type.')
            return FAILURE
        except RuleNotFound as error:
            logger.error(error)
            logger.debug('This means the rule you specified does not exist.')
            return error.error_code
        except UnsupportedOperation as error:
            logger.error(error)
            logger.debug('This means you cannot change the status of the DID.')
            return error.error_code
        except MissingDependency as error:
            logger.error(error)
            logger.debug('This means one dependency is missing.')
            return error.error_code
        except KeyError as error:
            if 'x-rucio-auth-token' in str(error):
                used_account = None
                try:  # get the configured account from the configuration file
                    used_account = '%s (from rucio.cfg)' % config_get('client', 'account')
                except:
                    pass
                try:  # are we overridden by the environment?
                    used_account = '%s (from RUCIO_ACCOUNT)' % os.environ['RUCIO_ACCOUNT']
                except:
                    pass
                logger.error('Specified account %s does not have an associated identity.' % used_account)
            else:
                logger.debug(traceback.format_exc())
                contact = config_get('policy', 'support', raise_exception=False)
                support = ('Please follow up with all relevant information at: ' + contact) if contact else ''
                logger.error('\nThe object is missing this property: %s\n'
                             'This should never happen. Please rerun the last command with the "-v" option to gather more information.\n'
                             '%s' % (str(error), support))
            return FAILURE
        except RucioException as error:
            logger.error(error)
            return error.error_code
        except Exception as error:
            if isinstance(error, IOError) and getattr(error, 'errno', None) == errno.EPIPE:
                # Ignore Broken Pipe
                # While in python3 we can directly catch 'BrokenPipeError', in python2 it doesn't exist.

                # Python flushes standard streams on exit; redirect remaining output
                # to devnull to avoid another BrokenPipeError at shutdown
                devnull = os.open(os.devnull, os.O_WRONLY)
                os.dup2(devnull, sys.stdout.fileno())
                return SUCCESS
            logger.debug(traceback.format_exc())
            logger.error(error)
            contact = config_get('policy', 'support', raise_exception=False)
            support = ("If it's a problem concerning your experiment or if you're unsure what to do, please follow up at: %s\n" % contact) if contact else ''
            contact = config_get('policy', 'support_rucio', default='https://github.com/rucio/rucio/issues')
            support += "If you're sure there is a problem with Rucio itself, please follow up at: " + contact
            logger.error('\nRucio exited with an unexpected/unknown error.\n'
                         'Please rerun the last command with the "-v" option to gather more information.\n'
                         '%s' % support)
            return FAILURE
    return new_funct

def get_client(args):
    """
    Returns a new client object.
    """
    if not args.auth_strategy:
        if 'RUCIO_AUTH_TYPE' in os.environ:
            auth_type = os.environ['RUCIO_AUTH_TYPE'].lower()
        else:
            try:
                auth_type = config_get('client', 'auth_type').lower()
            except (NoOptionError, NoSectionError):
                logger.error('Cannot get AUTH_TYPE')
                sys.exit(FAILURE)
    else:
        auth_type = args.auth_strategy.lower()

    if auth_type in ['userpass', 'saml'] and args.username is not None and args.password is not None:
        creds = {'username': args.username, 'password': args.password}
    elif auth_type == 'oidc':
        if args.oidc_issuer:
            args.oidc_issuer = args.oidc_issuer.lower()
        creds = {'oidc_auto': args.oidc_auto,
                 'oidc_scope': args.oidc_scope,
                 'oidc_audience': args.oidc_audience,
                 'oidc_polling': args.oidc_polling,
                 'oidc_refresh_lifetime': args.oidc_refresh_lifetime,
                 'oidc_issuer': args.oidc_issuer,
                 'oidc_username': args.oidc_username,
                 'oidc_password': args.oidc_password}
    elif auth_type == "x509":
        creds = {'client_cert': args.certificate, "client_key": args.client_key}
    else:
        creds = None

    try:
        client = Client(rucio_host=args.host, auth_host=args.auth_host,
                        account=args.account,
                        auth_type=auth_type, creds=creds,
                        ca_cert=args.ca_certificate, timeout=args.timeout,
                        user_agent=args.user_agent, vo=args.vo,
                        logger=logger)
    except CannotAuthenticate as error:
        logger.error(error)
        if 'alert certificate expired' in str(error):
            logger.error('The server certificate expired.')
        elif auth_type.lower() == 'x509_proxy':
            logger.error('Please verify that your proxy is still valid and renew it if needed.')
        sys.exit(FAILURE)
    return client

def __resolve_containers_to_datasets(scope, name, client):
    """
    Helper function to resolve a container into its dataset content.
    """
    datasets = []
    for did in client.list_content(scope, name):
        if did['type'] == 'DATASET':
            datasets.append({'scope': did['scope'], 'name': did['name']})
        elif did['type'] == 'CONTAINER':
            datasets.extend(__resolve_containers_to_datasets(did['scope'], did['name'], client))
    return datasets

# Function to parse filters from string with logical operators AND, OR to a list of dicts as in rucio's filter engine
def parse_filters(input_str):
    # Split by WORD "OR", to create separate dicts for OR conditions, avoiding splitting words like "ORIGINATOR"
    or_conditions = re.split(r'\bOR\b', input_str)
    filters = []

    for or_cond in or_conditions:
        # Same as for the "OR"
        and_conditions = re.split(r'\bAND\b', or_cond)
        and_dict = {}
        
        for cond in and_conditions:
            # Regex to capture key, operator, and value
            match = re.match(r'(\w+)\s*(LIKE|>=|<=|!=|>|<|=)\s*([^\s]+)', cond.strip())
            
            if match:
                field, operator, value = match.groups()
                #operator_key = get_operator_key(field, operator)
                and_dict[f"{field}.{operator}"] = value.strip() #and_dict[operator_key] = value.strip()
        
        filters.append(and_dict)

    return filters

@exception_handler
def customUpload(args): #--scope, --rse, --file, --name, --meta, --bulk-txt
    '''
    Custom upload: upload file + set-metadata from .json file

    :param file: file path of the data file
    :param meta: file path of the .json metadata file
    '''
    client = get_client(args)
    import random
    import string
    from rucio.client.uploadclient import UploadClient 
    uplc = UploadClient(client)

    try:
        # Handle bulk or individual input
        if args.bulk_txt.strip():
            data_meta_pairs = []
            with open(args.bulk_txt, 'r') as f:
                for idx, line in enumerate(f, start=1):
                    parts = line.strip().split()
                    if len(parts) == 3:
                        data_file, name, meta_file = parts
                    elif len(parts) == 2:
                        data_file, meta_file = parts
                        name = data_file.split('/')[-1]
                    else:
                        raise ValueError(f"Line {idx}: Expected 2 or 3 elements but found {len(parts)}")
                    data_meta_pairs.append((data_file, name, meta_file))
        else:
            if not (len(args.file) == len(args.meta)):
                raise ValueError("Mismatch in number of data and metadata files.")
            
            if args.name and len(args.name) > 0:
                if len(args.name) != len(args.file):
                    raise ValueError("If 'name' is provided, it must match the number of data files.")
                data_meta_pairs = list(zip(args.file, args.name, args.meta))
            else:
                data_meta_pairs = [(f, f.split('/')[-1], m) for f, m in zip(args.file, args.meta)]

        did_scope = args.scope
        upload_items = []

        for data_file, name, _ in data_meta_pairs:
            did_name = name.strip() or data_file.split('/')[-1]
            upload_items.append({
                'path': data_file,
                'rse': args.rse,
                'did_scope': did_scope,
                'did_name': did_name,
                'register_after_upload': True
            })

        # Upload
        try:
            uplc = UploadClient()
            uplc.upload(upload_items, summary_file_path='/tmp/rucio_upload.json')
        except NoFilesUploaded:
            return {"error": "No files uploaded", "uploaded": [], "failed_metadata": []}
        except NotAllFilesUploaded:
            logging.warning("Not all files uploaded. Checking summary...")
            with open("/tmp/rucio_upload.json", 'r', encoding='utf-8') as f:
                summary = json.load(f)
            success = []
            for file, name, meta in data_meta_pairs:
                did_name = name.strip() or file.split('/')[-1]
                if f"{did_scope}:{did_name}" in summary:
                    success.append((file, name, meta))
                else:
                    logging.warning(f"Upload failed: {did_scope}:{did_name}")
            data_meta_pairs = success
        except Exception as e:
            return {"error": f"Upload failed: {e}", "uploaded": [], "failed_metadata": []}

        logging.info("Setting metadata for uploaded files...")
        time.sleep(1.0)

        timestamp = datetime.now().strftime("%Y-%m-%dT%H:%M:%S.%f")
        suffix = ''.join(random.choices(string.ascii_letters + string.digits, k=7))
        start_file = f"{did_scope}_{timestamp}_{suffix}_START.json"
        end_file = f"{did_scope}_{timestamp}_{suffix}_END.json"

        try:
            client.set_metadata(scope=did_scope, name=start_file, key="JSON", value="json_string")
        except Exception as e:
            logging.error(f"Failed to set START metadata: {e}")
            return {"error": "Failed to set START metadata", "uploaded": [f for f, _, _ in data_meta_pairs], "failed_metadata": "ALL"}

        failed_metadata = []

        for i, (data_file, name, meta_file) in enumerate(data_meta_pairs):
            did_name = name.strip() or data_file.split('/')[-1]
            try:
                with open(meta_file, 'r') as f:
                    metadata = json.load(f)
                    metadata['LINK'] = f'{did_scope}:{did_name}'
                    metadata['sha256'] = sha256(data_file)
                    metadata_json = json.dumps(metadata)

                meta_name = f"{did_scope}_{timestamp}_{suffix}_{i}.json"
                client.set_metadata(scope=did_scope, name=meta_name, key="JSON", value=metadata_json)
            except Exception as e:
                logging.error(f"Failed to set metadata for {did_scope}:{did_name}: {e}")
                failed_metadata.append(f"{did_scope}:{did_name}")

        try:
            client.set_metadata(scope=did_scope, name=end_file, key="JSON", value="json_string")
        except Exception as e:
            logging.warning(f"Failed to set END metadata marker: {e}")

        MAX_SUCCESS_DISPLAY = 10
        success_files = [
            f"{did_scope}:{name.strip() or f.split('/')[-1]}"
            for f, name, _ in data_meta_pairs
            if f"{did_scope}:{name.strip() or f.split('/')[-1]}" not in failed_metadata
        ]

        return {
            "success_count": len(success_files),
            "success": success_files[:MAX_SUCCESS_DISPLAY],
            "failed_metadata": failed_metadata
        }

    except Exception as e:
        logging.exception("Unexpected error during upload/metadata process.")
        return {"error": str(e), "uploaded": [], "failed_metadata": []}

    
# Custom download for IDL-rucio Innovation Grant
def customDownload(args): #--scope, --file, --base_dir, --no_subdir, --bulk
    if args.bulk:
        raise NotImplementedError #customDownloadBulk(items=[{'did': did, 'base_dir': args.base_dir, 'no_subdir': args.no_subdir}])
    else:
        client = get_client(args)
        from rucio.client.downloadclient import DownloadClient
        dwnc = DownloadClient(client=client, logger=logger) #, check_admin=args.allow_tape
        
        name = args.file 
        did = f"{args.scope}:{name}"
        
        dwn_file = dwnc.download_dids(items=[{'did': did, 'base_dir': args.base_dir, 'no_subdir': args.no_subdir}])

        import random
        import string
        time_of_set_operation = datetime.now().strftime("%Y-%m-%dT%H:%M:%S.%f")
        random_7_digits = ''.join(random.choices(string.ascii_letters + string.digits, k=7))
        start_file = f"{args.scope}_{time_of_set_operation}_{random_7_digits}|get-metadata_handling:START" # 100 characters without the real name
        end_file = f"{args.scope}_{time_of_set_operation}_{random_7_digits}|get-metadata_handling:END" # 98 characters without the real name

        hash_data = sha256(dwn_file[0]['temp_file_path'][:-5])
        check_name = f"{args.scope}_{time_of_set_operation}_{random_7_digits}|" + hash_data + ":" + name

        _ = client.get_metadata(scope="START", name=start_file, plugin="IDL")

        time.sleep(0.5) # Wait for the tmp folder to be created

        _ = client.get_metadata(scope=args.scope, name=check_name, plugin="IDL")

        time.sleep(1.0) # Wait for the metadata to be written in the tmp folder

        meta = client.get_metadata(scope="END", name=end_file, plugin="IDL")


# Not needed for the IDL project
# def customSetMeta(args):
#     '''
#     Custom set-metadata: set-metadata from .json file if you need to edit the metadata of a DID

#     :param file: file path of the data file
#     :param meta: file path of the .json metadata file
#     '''
#     client = get_client(args)
#     import random
#     import string
#     from rucio.client.uploadclient import UploadClient 
#     uplc = UploadClient(client)
    
#     try:
#         # Bulk upload from a .txt file with a data pfn metadata pfn pair, separated by a space, for each line
#         if args.bulk_txt != " ":
#             data_meta_pairs = []
#             try:
#                 with open(args.bulk_txt, 'r') as f:
#                     for idx, line in enumerate(f, start=1):
#                         line = line.strip().split()
#                         # Verify the schema of the .txt file
#                         #if len(line) != 2:
#                         #    raise Exception(f"Line {idx}: Expected 2 elements but found {len(line)}")
#                         data_file, meta_file = line
#                         data_meta_pairs.append((data_file, meta_file))
#             except Exception as e:
#                 logging.error(f"{e}")
#         else:
#             # File and metadata pairs must be of the same number 
#             if len(args.file) != len(args.meta):
#                 raise Exception("The number of data files and metadata files must be the same.")
#             data_meta_pairs = list(zip(args.file, args.meta))

#         did_scope = args.scope
        
#         time_of_set_operation = datetime.now().strftime("%Y-%m-%dT%H:%M:%S.%f")
#         random_7_digits = ''.join(random.choices(string.ascii_letters + string.digits, k=7))
#         start_file = f"{did_scope}_{time_of_set_operation}_{random_7_digits}_START.json"
#         end_file = f"{did_scope}_{time_of_set_operation}_{random_7_digits}_END.json"

#         client.set_metadata(scope=did_scope, name=start_file, key="JSON", value="json_string")

#         i = 0
#         for file, meta in data_meta_pairs:
#             did_name = file.split('/')[-1] # Use the file name as the DID name            
#             try:
#                 # Parse the JSON file in a Python dict and add the "DID" and "sha-256" metadata
#                 with open(meta, 'r') as m:
#                     json_dict = json.load(m)
#                     json_dict['LINK'] = f'{did_scope}:{did_name}'
#                     json_dict['sha256'] = sha256(file)
#                     json_string = json.dumps(json_dict)

#                 # Set the metadata for the uploaded file
#                 client.set_metadata(scope=did_scope, name=f"{did_scope}_{time_of_set_operation}_{random_7_digits}_{i}.json", key="JSON", value=json_string)
#                 i += 1
#             except Exception as e:
#                 raise Exception("ERROR: Set-metadata failed")
        
#         client.set_metadata(scope=did_scope, name=end_file, key="JSON", value="json_string")

#     except Exception as e:
#         raise

# Custom get-metadata for IDL-rucio Innovation Grant, it computes the sha-256 of the file and then gets the metadata from the custom plugin using the AyraDB cluster
def customGetMeta(args): #--plugin, dids
    '''
    Custom get-metadata: get-metadata of the specific DID for the custom plugin "IDL"

    :param file: file path of the data file
    :param meta: file path of the .json metadata file
    '''
    client = get_client(args)
    if args.plugin == "IDL":
        # Bulk upload from a .txt file with a data pfn metadata pfn pair, separated by a space, for each line
        if args.bulk_txt != " ":
            did_list = []
            try:
                with open(args.bulk_txt, 'r') as f:
                    for idx, line in enumerate(f, start=1):
                        line = line.strip().split()
                        # Verify the schema of the .txt file
                        if len(line) != 1:
                            raise Exception(f"Line {idx}: Expected 1 element for line, but found {len(line)}")
                        did_list.append(line)
            except Exception as e:
                logging.error(f"{e}")
        else:
            did_list = args.dids

        import random
        import string
        # this version only works if all the dids are from the same scope
        did_scope = did_list[0].split(':')[0]
        time_of_set_operation = datetime.now().strftime("%Y-%m-%dT%H:%M:%S.%f")
        random_7_digits = ''.join(random.choices(string.ascii_letters + string.digits, k=7))
        start_file = f"{did_scope}_{time_of_set_operation}_{random_7_digits}|get-metadata_handling:START" # 59 characters without the real name
        end_file = f"{did_scope}_{time_of_set_operation}_{random_7_digits}|get-metadata_handling:END" # 57 characters without the real name

        _ = client.get_metadata(scope="START", name=start_file, plugin=args.plugin)

        time.sleep(0.5) # Wait for the tmp folder to be created

        try:
            for did in did_list:
                scope = did.split(':')[0]
                name = did.split(':')[1]
                # Handling of the get-metadata logic in the IDL's plugin 
                name = f'{did_scope}_{time_of_set_operation}_{random_7_digits}|get-metadata_handling:' + name
                # Get metadatas for the DIDs
                _ = client.get_metadata(scope=scope, name=name, plugin=args.plugin)
        except Exception as e:
            raise Exception(f"Error:{e}")

        time.sleep(1.0) # Wait for the DIDs to be written in the tmp file
        
        metas = client.get_metadata(scope="END", name=end_file, plugin=args.plugin)
        metas = metas["Output"]

        try:
            for i, meta in enumerate(metas):
                if i > 0:
                    print('------')
                table = [(k + ':', str(v)) for (k, v) in sorted(meta.items())]
                print(tabulate(table, tablefmt='plain', disable_numparse=True))
            return SUCCESS
        except Exception as e:
            print(f"Error:{e}")
    else:
        try:
            for i, did in enumerate(args.dids):
                if i > 0:
                    print('------')
                scope, name = get_scope(did, client)
                meta = client.get_metadata(scope=scope, name=name, plugin="DID_COLUMN")
                table = [(k + ':', str(v)) for (k, v) in sorted(meta.items())]
                print(tabulate(table, tablefmt='plain', disable_numparse=True))
            return SUCCESS
        except Exception as e:
            raise Exception(f"ERROR: {e}")

@exception_handler
def customListDids(args):
    client = get_client(args)
    did_scope = args.scope

    try:
        filters = parse_filters(args.filters)

        # Convert date fields to np.datetime64 for AyraDB compatibility
        # This is necessary because AyraDB expects date fields in a specific format
        for fil in filters:
            for key, value in fil.items():
                if key.startswith(("EPOCH", "CREATION_DATE", "DATE_END", "DATE_OBS", "DATE", "UPDATE_TIME")):
                    fil[key] = np.datetime64(f'{value}')

        # Build the SELECT: default to LINK if not provided
        if args.select:
            select_fields = args.select + ", LINK"
        else:
            select_fields = "LINK"

        filters.append({'sql_select': select_fields})
        output = list(client.list_dids(scope=did_scope, filters=filters, did_type='all', long=False, recursive=False))
        res = output[:-1]  # Exclude the last element which is the total count and limited status

        if not args.select:
            # Simple list-dids mode
            table = []
            for d in res:
                link = d["LINK"]
                scope_res, name_res = link.split(":")
                meta = client.get_metadata(plugin="DID_COLUMN", scope=scope_res, name=name_res)
                did_type = meta["did_type"]
                table.append([f"{scope_res}:{name_res}", did_type])
            print(tabulate(table, tablefmt=tablefmt, headers=["SCOPE:NAME", "[DID TYPE]"]))

        else:
            # Query mode with SELECT
            for d in res:
                link = d["LINK"]
                scope_res, name_res = link.split(":")
                meta = client.get_metadata(plugin="DID_COLUMN", scope=scope_res, name=name_res)
                did_type = meta["did_type"]
                header_table = [[f"{scope_res}:{name_res}", did_type]]
                print(tabulate(header_table, tablefmt=tablefmt, headers=[]))

                table = []
                for key, value in d.items():
                    if key != "LINK":
                        table.append([key, value])
                print(tabulate(table, tablefmt=tablefmt, headers=["SELECT", "VALUE"]))

                import shutil
                print("\\" * shutil.get_terminal_size().columns)
        
        print(f"Total DIDs found: {output[-1]['total_count']}.")
        if output[-1]['limited']:
            print("The DIDs shown here are limited to 10000 records.")

    except Exception as e:
        print(f"Error: {e}")

# Customization WIP...
@exception_handler
def delete_metadata(args): # did
    client = get_client(args)
    try:
        for did in args.did:
            did_scope = did.split(":")[0]
            did_name = did.split(":")[1]
            filters = "Work = Around"
            filters = parse_filters(filters)
            filters.append({"del_select": did_name})
            print(type(filters))
            result = client.list_dids(scope=did_scope, filters=filters, did_type='all', long=False, recursive=False)
            result = list(result)
            if result == ["delete"]:
                print(f"Metadata of DID: {did_scope}:{did_name} DELETED")
    except Exception as e:
        print(f"Error: {e}")

def get_parser():
    """
    Returns the argparse parser.
    """
    oparser = argparse.ArgumentParser(prog=os.path.basename(sys.argv[0]), add_help=True)
    subparsers = oparser.add_subparsers()

    # Main arguments
    oparser.add_argument('--version', action='version', version='%(prog)s ' + version.version_string())
    oparser.add_argument('--config', dest="config", help="The Rucio configuration file to use.")
    oparser.add_argument('--verbose', '-v', default=False, action='store_true', help="Print more verbose output.")
    oparser.add_argument('-H', '--host', dest="host", metavar="ADDRESS", help="The Rucio API host.")
    oparser.add_argument('--auth-host', dest="auth_host", metavar="ADDRESS", help="The Rucio Authentication host.")
    oparser.add_argument('-a', '--account', dest="account", metavar="ACCOUNT", help="Rucio account to use.")
    oparser.add_argument('-S', '--auth-strategy', dest="auth_strategy", default=None, help="Authentication strategy (userpass, x509...)")
    oparser.add_argument('-T', '--timeout', dest="timeout", type=float, default=None, help="Set all timeout values to seconds.")
    oparser.add_argument('--robot', '-R', dest="human", default=True, action='store_false', help="All output in bytes and without the units. This output format is preferred by parsers and scripts.")
    oparser.add_argument('--user-agent', '-U', dest="user_agent", default='rucio-clients', action='store', help="Rucio User Agent")
    oparser.add_argument('--vo', dest="vo", metavar="VO", default=None, help="VO to authenticate at. Only used in multi-VO mode.")
    oparser.add_argument('--rucio', type=str, help="Flag to choose the Rucio command instead of the IDL one.")

    # Options for the userpass or OIDC auth_strategy
    oparser.add_argument('-u', '--user', dest='username', default=None, help='username')
    oparser.add_argument('-pwd', '--password', dest='password', default=None, help='password')
    # Options for defining remaining OIDC parameters
    oparser.add_argument('--oidc-user', dest='oidc_username', default=None, help='OIDC username')
    oparser.add_argument('--oidc-password', dest='oidc_password', default=None, help='OIDC password')
    oparser.add_argument('--oidc-scope', dest='oidc_scope', default='openid profile', help='Defines which (OIDC) information user will share with Rucio. '
                         + 'Rucio requires at least -sc="openid profile". To request refresh token for Rucio, scope must include "openid offline_access" and '  # NOQA: W503
                         + 'there must be no active access token saved on the side of the currently used Rucio Client.')  # NOQA: W503
    oparser.add_argument('--oidc-audience', dest='oidc_audience', default=None, help='Defines which audience are tokens requested for.')
    oparser.add_argument('--oidc-auto', dest='oidc_auto', default=False, action='store_true', help='If not specified, username and password credentials are not required and users will be given a URL '
                         + 'to use in their browser. If specified, the users explicitly trust Rucio with their IdP credentials.')  # NOQA: W503
    oparser.add_argument('--oidc-polling', dest='oidc_polling', default=False, action='store_true', help='If not specified, user will be asked to enter a code returned by the browser to the command line. '
                         + 'If --polling is set, Rucio Client should get the token without any further interaction of the user. This option is active only if --auto is *not* specified.')  # NOQA: W503
    oparser.add_argument('--oidc-refresh-lifetime', dest='oidc_refresh_lifetime', default=None, help='Max lifetime in hours for this an access token will be refreshed by asynchronous Rucio daemon. '
                         + 'If not specified, refresh will be stopped after 4 days. This option is effective only if --oidc-scope includes offline_access scope for a refresh token to be granted to Rucio.')  # NOQA: W503
    oparser.add_argument('--oidc-issuer', dest='oidc_issuer', default=None,
                         help='Defines which Identity Provider is going to be used. The issuer string must correspond '
                         + 'to the keys configured in the /etc/idpsecrets.json auth server configuration file.')  # NOQA: W503

    # Options for the x509  auth_strategy
    oparser.add_argument('--certificate', dest='certificate', default=None, help='Client certificate file for x509 Authentication.')
    oparser.add_argument('--client_key', dest='client_key', default=None, help='Client key for x509 Authentication.')
    oparser.add_argument('--ca-certificate', dest='ca_certificate', default=None, help='CA certificate to verify peer against (SSL).')

    # The list-dids command
    list_parser = subparsers.add_parser('list-dids', help='List DIDs matching the filters, optionally with select fields') 
    list_parser.set_defaults(function=customListDids)
    #list_parser.add_argument("--plugin", choices=['IDL', 'DID_COLUMN'], default="IDL", type=str, help="Plugin to be used. Default: 'IDL'")
    list_parser.add_argument("--filters", type=str, default=[], help="Filters to apply. Operators must belong to the set of (LIKE, <=, >=, =, !=, >, <) and the logical expressions AND and OR can be used.")
    list_parser.add_argument("--scope", type=str, required=True, help="Scope of the DIDs to list")
    list_parser.add_argument("--select", type=str, help="Comma-separated list of fields to select. The LINK, which is the DID, is always present in the selects")

    # Subparser delete-metadata 
    pars_sql = subparsers.add_parser("delete-metadata", help="List of DIDs satisfying the filters, each one in a dictionary where the key are the SELECTs")
    pars_sql.set_defaults(function=delete_metadata)
    # Get's args and flags
    pars_sql.add_argument("--did", type=str, nargs='+', help="DIDs for which metadata in AyraDB need to be deleted.")

    # Subparser upload
    pars_upload = subparsers.add_parser("upload", help="Upload and set-metadata of one or multiple files.")
    pars_upload.set_defaults(function=customUpload)
    # Upload's args and flags
    pars_upload.add_argument("--scope", type=str, required=True, help="Scope")
    pars_upload.add_argument("--rse", type=str, required=True, help="RSE expression")
    pars_upload.add_argument("--file", type=str, nargs='+', help="Specifies the path to the data files")
    pars_upload.add_argument("--name", type=str, nargs='+', help="Optional did names for the data files. If not provided, the file name will be used as the did name.")
    pars_upload.add_argument("--meta", type=str, nargs='+', help="Specifies the path to the metadata files")
    pars_upload.add_argument("--bulk-txt", default=" ", type=str, help="Specifies the path to a .txt file for bulk upload. The .txt file must contain two columns per line: the first column is the path to the data file and the second is the path to the corresponding metadata file.")

    #pars_upload.add_argument("--plugin", default="IDL", type=str, help="Plugin to use. Default: 'IDL'")
    # pars_upload.add_argument("--bulk", action='store_true', help="Flag to bulk upload data and metadata files.")
    # pars_upload.add_argument("--txt", type=str, help="Path to a .txt file containing data file and metadata file paths on each line.")

    # Subparser download
    pars_download = subparsers.add_parser("download", help="Download a DID")
    # Download's args and flags
    pars_download.set_defaults(function=customDownload)
    pars_download.add_argument("--scope", type=str, required=True, help="Scope")
    pars_download.add_argument("--file", type=str, required=True, help="File path of the data file")
    pars_download.add_argument("--base_dir", type=str, default=os.path.expanduser("~"), help="Base directory where the downloaded files will be stored. Default: '~'")
    pars_download.add_argument("--no_subdir", type=bool, default=False, help="If true, files are written directly into base_dir. Default: False")
    pars_download.add_argument("--bulk", type=bool, default=False, help="Download a list of files. Default: False [TO BE IMPLEMENTED]")
    
    # Subparser get-metadata
    pars_get = subparsers.add_parser("get-metadata", help="Get-metadata of a file")
    pars_get.set_defaults(function=customGetMeta)
    # Get's args and flags
    pars_get.add_argument("--plugin", choices=['IDL', 'DID_COLUMN'], default="IDL", type=str, help="Plugin to use. Default: 'IDL'")
    #pars_get.add_argument("--scope", type=str, help="Scope")
    #pars_get.add_argument("--name", type=str, help="Name of the DID")
    pars_get.add_argument("dids", type=str, nargs='+', help="List of DIDs" )
    pars_get.add_argument("--bulk-txt", default=" ", type=str, help="Specifies the path to a .txt file for bulk get-metadata. The .txt file must contain one for each line the DIDs to get-metadata.")

    # The set-metadata subparser
    # set_metadata_parser = subparsers.add_parser("set-meta", help="Upload and set-metadata of one or multiple files.")
    # set_metadata_parser.set_defaults(function=customSetMeta)
    # Set-metadata's args and flags
    # set_metadata_parser.add_argument("--scope", type=str, required=True, help="Scope")
    # set_metadata_parser.add_argument("--file", type=str, nargs='+', help="Specifies the path to the data files")
    # set_metadata_parser.add_argument("--meta", type=str, nargs='+', help="Specifies the path to the metadata files")
    # set_metadata_parser.add_argument("--bulk-txt", default=" ", type=str, help="Specifies the path to a .txt file for bulk upload. The .txt file must contain two columns per line: the first column is the path to the data file and the second is the path to the corresponding metadata file.")

    return oparser     

def call_rucio():
    """Forward all arguments dynamically to rucio"""
    cmd = ["rucio"] + sys.argv[1:]  # Pass all arguments
    error = subprocess.run(cmd, capture_output=True, text=True).stderr.strip()
    if error == "":
        print(subprocess.run(cmd, capture_output=True, text=True).stdout.strip())
    else:
        raise Exception(f"\033[1;31mERROR: {error}\033[30m")

def call_rucio_admin():
    """Forward all arguments dynamically to rucio-admin"""
    cmd = ["rucio-admin"] + sys.argv[1:]  # Pass all arguments
    error = subprocess.run(cmd, capture_output=True, text=True).stderr.strip()
    if error == "":
        print(subprocess.run(cmd, capture_output=True, text=True).stdout.strip())
    else:
        raise Exception(f"\033[1;31mERROR: {error}\033[0m")


if __name__ == '__main__':
    
    oparser = get_parser()
    
    if EXTRA_MODULES['argcomplete']:
        argcomplete.autocomplete(oparser)
    #argcomplete.autocomplete(oparser)

    if len(sys.argv) == 1:
        oparser.print_help()
        sys.exit(FAILURE)

    cmd = sys.argv[1]  # Extract the method name
    is_rucio = '--rucio' in sys.argv
    arguments = sys.argv[1:]

    try:
        if cmd in IDL_COMMANDS and cmd not in RUCIO_COMMANDS:
            # set the configuration before anything else, if the config parameter is present
            for argi in range(len(arguments)):
                if arguments[argi] == '--config' and (argi + 1) < len(arguments):
                    os.environ['RUCIO_CONFIG'] = arguments[argi + 1]
            args = oparser.parse_args(arguments)
            logger = setup_logger(module_name=__name__, logger_name='user', verbose=args.verbose)
            start_time = time.time()
            result = args.function(args)
            end_time = time.time()
            if args.verbose:
                print("Completed in %-0.4f sec." % (end_time - start_time))
            sys.exit(result)
        if cmd in IDL_COMMANDS and cmd in RUCIO_COMMANDS and not is_rucio:
            # set the configuration before anything else, if the config parameter is present
            for argi in range(len(arguments)):
                if arguments[argi] == '--config' and (argi + 1) < len(arguments):
                    os.environ['RUCIO_CONFIG'] = arguments[argi + 1]
            args = oparser.parse_args(arguments)
            logger = setup_logger(module_name=__name__, logger_name='user', verbose=args.verbose)
            start_time = time.time()
            result = args.function(args)
            end_time = time.time()
            if args.verbose:
                print("Completed in %-0.4f sec." % (end_time - start_time))
            sys.exit(result)
        elif cmd in IDL_COMMANDS and cmd in RUCIO_COMMANDS and is_rucio:
            sys.argv.pop(sys.argv.index('--rucio'))
            print(sys.argv)
            call_rucio()
        elif cmd in RUCIO_COMMANDS and cmd not in IDL_COMMANDS:
            call_rucio()
        elif cmd in RUCIO_ADMIN_COMMANDS:
            call_rucio_admin()
        else:
            COMMANDS = {"IDL": IDL_COMMANDS, "rucio": RUCIO_COMMANDS, "rucio-admin": RUCIO_ADMIN_COMMANDS}
            PRETTY_COMMANDS = json.dumps(COMMANDS)
            raise Exception(f"""\033[1;31mERROR: choose from these commands: 
{{"IDL": {IDL_COMMANDS},

"rucio": {RUCIO_COMMANDS},

"rucio-admin": {RUCIO_ADMIN_COMMANDS}}}\033[0m""")
    except Exception as e:
        logging.error(f"{e}")